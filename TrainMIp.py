{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TrainMIp.py","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMn9rCKb5x6cmp3qG6dbPL1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"b3ADSfXnF29R","colab_type":"code","colab":{}},"source":["!pip install -U -q PyDrive\n"," \n","from pydrive.auth import GoogleAuth\n"," \n","from pydrive.drive import GoogleDrive\n"," \n","from google.colab import auth\n"," \n","from oauth2client.client import GoogleCredentials\n"," \n","auth.authenticate_user()\n"," \n","gauth = GoogleAuth()\n"," \n","gauth.credentials = GoogleCredentials.get_application_default()\n"," \n","drive = GoogleDrive(gauth)\n","\n","from keras.models import Sequential\n","import scipy.io\n","import numpy\n","import sys\n","from keras.layers.core import Dense, Activation\n","from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Nadam\n","import h5py\n","# from  normalize_data import normalize,denormalize\n","from sklearn.model_selection import train_test_split\n","from keras.utils.generic_utils import Progbar\n","from keras.callbacks import EarlyStopping\n","import os\n","from keras.callbacks import TensorBoard\n","import ntpath\n","import logging\n","from keras.callbacks import ModelCheckpoint\n","import glob, os\n","\n","cnfg = sys.argv[1];\n","datafile = sys.argv[2];\n","mdlfile = sys.argv[3];\n","pred_path = sys.argv[4];\n","test_path = sys.argv[5];\n","# train_flag = int(sys.argv[4]);\n","newDict = {}\n","\n","with open(cnfg) as f:\n","    for line in f:\n","        line = line.rstrip('\\n')\n","        print(line)\n","        splitLine = line.split(':')\n","        if ((splitLine[0] == 'indim') | (splitLine[0] == 'outdim') | (splitLine[0] == 'nbepochs') | (\n","                splitLine[0] == 'batchsize') | (splitLine[0] == 'normalizex') | (splitLine[0] == 'normalizey')):\n","            newDict[(splitLine[0])] = int(splitLine[1].rstrip())\n","        elif (splitLine[0] == 'loss'):\n","            newDict[(splitLine[0])] = (splitLine[1].strip())\n","        else:\n","            line = splitLine[1];\n","            line = line.split(' ')\n","            newDict[(splitLine[0])] = line\n","\n","#    if(splitLine[0]!='nbepochs'):\n","# mdlfile = mdlfile+splitLine[0]+'_'+ str(newDict[(splitLine[0])])\n","\n","# name=os.path.splitext(datafile)[0]\n","# C= name.split('/')\n","# print C[-1],C[-2]\n","# mdlfile = C[-1]+'_'+C[-2]+'_'+xname+'_'+yname;\n","directory = './models/' + mdlfile;\n","logging.basicConfig(level=logging.DEBUG)\n","\n","print(directory)\n","\n","os.system('cp ' + cnfg + ' ' + directory + '/nnet_config.txt')\n","\n","print(newDict)\n","# nins = newDict['indim']\n","# nouts = newDict['outdim']\n","activations = newDict['activation']\n","\n","hiddenlayers = newDict['hiddenlayers']\n","hiddenlayers = [x for x in hiddenlayers if (x != '')]\n","\n","data = scipy.io.loadmat(Data);\n","Xtrain = data['train_data']\n","Ytrain = data['train_lab']\n","\n","Xval = data['val_data']\n","Yval = data['val_lab']\n","\n","Xtest = data['test_data']\n","Ytest = data['test_lab']\n","\n","# Ytrain = numpy.log(Ytrain)\n","print(Xtrain.shape)\n","if (newDict['normalizex'] == 1):\n","    print(\"normalizing input data\")\n","    mux = numpy.mean(Xtrain, axis=0);\n","    sigmax = numpy.std(Xtrain, axis=0);\n","    print(mux.shape, sigmax.shape)\n","    sigmax[sigmax < 1e-5] = 1;\n","    numpy.savetxt(directory + '/mux.txt', mux);\n","    numpy.savetxt(directory + '/sigmax.txt', sigmax);\n","    Xtrain = (Xtrain - mux) / sigmax;\n","    Xval = (Xval - mux) / sigmax;\n","    Xtest = (Xtest - mux) / sigmax;\n","\n","print('number of infinite values:' + str(sum(sum(~numpy.isfinite(Xtrain)))))\n","xtrain_size = Xtrain.shape\n","ytrain_size = Ytrain.shape\n","print('input number of greater than +-1:' + str(sum(sum(abs(Xtrain) > 1)) * 100.00 / (xtrain_size[0] * xtrain_size[1])))\n","print('input data dimention is ' + str(Xtrain.shape))\n","model = Sequential()\n","print('..building model')\n","print('creating the layer: Input {} -> Output {} with activation {}'.format(Xtrain.shape[1], int(hiddenlayers[1]),\n","                                                                            activations[0]))\n","model.add(Dense(output_dim=int(hiddenlayers[1]), input_dim=Xtrain.shape[1], activation=activations[0]))\n","for k in xrange(2, len(hiddenlayers) - 1):\n","    print('creating the layer: Input {} -> Output {} with activation {}'.format(int(hiddenlayers[k - 1]),\n","                                                                                int(hiddenlayers[k]), activations[k]))\n","    model.add(Dense(output_dim=int(hiddenlayers[k]), activation=activations[k]))\n","\n","print('creating the layer: Input {} -> Output {} with activation {}'.format(int(hiddenlayers[len(hiddenlayers) - 2]),\n","                                                                            Ytrain.shape[1], activations[-1]))\n","model.add(Dense(output_dim=int(Ytrain.shape[1]), activation=activations[-1]))\n","\n","print('..compiling model')\n","model.compile(loss=newDict['loss'], optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n","              metrics=['accuracy'])\n","\n","print('..fitting model')\n","batch_size = int(newDict['batchsize'])\n","early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n","checkpointer = ModelCheckpoint(filepath='saved_weight.hdf5', verbose=1, save_best_only=True)\n","history2 = model.fit(Xtrain, Ytrain, nb_epoch=int(newDict['nbepochs']), batch_size=int(newDict['batchsize']),\n","                     validation_data=(Xval, Yval), callbacks=[early_stopping, checkpointer])\n","model.load_weights('saved_weight.hdf5')\n","list1 = glob.glob(test_path + \"*.mat\");\n","\n","for k in list1:\n","    print('processing ' + k)\n","    st = k.split('/');\n","    name = st[-1]\n","    data = scipy.io.loadmat(k)\n","    Xtest = data['all_data'].transpose();\n","    Xtest = (Xtest - mux) / sigmax;\n","    pred = model.predict(Xtest, verbose=1);\n","    scipy.io.savemat(pred_path + name, {'pred': pred})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H2wS6hhZHJBO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":129},"executionInfo":{"status":"error","timestamp":1598216328366,"user_tz":-180,"elapsed":1294,"user":{"displayName":"Ay≈üenur YILMAZ","photoUrl":"","userId":"10129096605066158799"}},"outputId":"bf27d7a1-6017-430e-ad45-42760430ff03"},"source":["Data\\ Data_For_USC_2008_02_118_medium.avi"],"execution_count":8,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-060e5ba545bc>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Data\\ Data_For_USC_2008_02_118_medium.avi\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"]}]}]}